{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING.ipynb - Modifikasi untuk ekstraksi fitur\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "# Load model bahasa Indonesia\n",
    "nlp = spacy.blank('id')\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessing teks putusan\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalisasi teks\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)  # Hapus tanda baca\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()   # Normalisasi spasi\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_metadata_features(row):\n",
    "    \"\"\"Ekstraksi fitur dari metadata\"\"\"\n",
    "    features = {\n",
    "        'case_id': row.name + 1,\n",
    "        'no_perkara': row['nomor'],\n",
    "        'tanggal': row['tanggal'],\n",
    "        'jenis_perkara': row['jenis_perkara'],\n",
    "        'pasal': extract_pasal(row['pasal']),\n",
    "        'amar': preprocess_text(row['amar'])\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def extract_pasal(text):\n",
    "    \"\"\"Ekstrak pasal yang relevan\"\"\"\n",
    "    pasal = re.findall(r'pasal\\s+\\d+\\s+(?:ayat\\s+\\d+)?\\s*(?:huruf\\s+[a-z])?\\s*(?:undang-undang|uu|kuhp|kuh per)', text, flags=re.IGNORECASE)\n",
    "    return '; '.join(pasal) if pasal else \"\"\n",
    "\n",
    "def extract_key_content(text):\n",
    "    \"\"\"Ekstrak konten kunci dari teks putusan\"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    # Cari bagian fakta\n",
    "    fakta = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if 'm e n g a d i l i' in sent.lower() or 'menimbang' in sent.lower():\n",
    "            start_idx = i\n",
    "            break\n",
    "    \n",
    "    # Ambil 10 kalimat setelah \"mengadili\"\n",
    "    fakta = ' '.join(sentences[start_idx:start_idx+10])\n",
    "    \n",
    "    # Cari amar putusan\n",
    "    amar = \"\"\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if 'm e m u t u s k a n' in sent.lower() or 'memutuskan' in sent.lower():\n",
    "            amar = ' '.join(sentences[i:i+5])\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'ringkasan_fakta': preprocess_text(fakta),\n",
    "        'argument_hukum': preprocess_text(amar),\n",
    "        'text_length': len(text.split())\n",
    "    }\n",
    "\n",
    "def process_all_documents(df):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            # Baca teks putusan\n",
    "            with open(f'data/raw/case_{idx+1:03d}.txt', 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            # Ekstrak fitur\n",
    "            features = extract_metadata_features(row)\n",
    "            content_features = extract_key_content(text)\n",
    "            \n",
    "            # Gabungkan semua fitur\n",
    "            features.update(content_features)\n",
    "            features['text_full'] = preprocess_text(text)\n",
    "            results.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing case {idx+1}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_csv('data/metadata_raw.csv')\n",
    "\n",
    "# Proses semua dokumen\n",
    "processed_df = process_all_documents(df)\n",
    "\n",
    "# Simpan hasil\n",
    "processed_df.to_csv('data/processed/cases.csv', index=False)\n",
    "processed_df.to_json('data/processed/cases.json', orient='records', force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
