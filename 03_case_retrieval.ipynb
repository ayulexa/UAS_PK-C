{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT.ipynb - Modifikasi untuk retrieval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Persiapan Data\n",
    "df = pd.read_csv('data/processed/cases.csv')\n",
    "\n",
    "# Contoh query untuk evaluasi\n",
    "queries = {\n",
    "    \"q1\": {\n",
    "        \"text\": \"penyalahgunaan narkotika jenis sabu seberat 0.5 gram\",\n",
    "        \"relevant_cases\": [5, 12, 18]  # ID kasus yang relevan\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"text\": \"pengedar ganja dengan barang bukti 1 kilogram\",\n",
    "        \"relevant_cases\": [3, 7, 22]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('data/eval', exist_ok=True)\n",
    "\n",
    "with open('data/eval/queries.json', 'w') as f:\n",
    "    json.dump(queries, f)\n",
    "\n",
    "# 2. Pendekatan TF-IDF\n",
    "def tfidf_retrieval():\n",
    "    # Buat vektor dokumen\n",
    "    tfidf = TfidfVectorizer()\n",
    "    doc_vectors = tfidf.fit_transform(df['ringkasan_fakta'])\n",
    "\n",
    "    # Fungsi retrieval\n",
    "    def retrieve(query, k=5):\n",
    "        query_vec = tfidf.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, doc_vectors)\n",
    "        top_k_indices = np.argsort(similarities[0])[-k:][::-1]\n",
    "        return df.iloc[top_k_indices]['case_id'].tolist()\n",
    "\n",
    "    return retrieve\n",
    "\n",
    "# 3. Pendekatan BERT\n",
    "def bert_retrieval():\n",
    "    # Load model dan tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')\n",
    "    model = BertModel.from_pretrained('indobenchmark/indobert-base-p2')\n",
    "\n",
    "    # Encode semua dokumen\n",
    "    doc_embeddings = []\n",
    "    for text in tqdm(df['ringkasan_fakta']):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=256)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        doc_embeddings.append(outputs.last_hidden_state[:,0,:].numpy())\n",
    "\n",
    "    doc_embeddings = np.vstack(doc_embeddings)\n",
    "\n",
    "    # Fungsi retrieval\n",
    "    def retrieve(query, k=5):\n",
    "        inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True, max_length=256)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        query_embedding = outputs.last_hidden_state[:,0,:].numpy()\n",
    "\n",
    "        similarities = cosine_similarity(query_embedding, doc_embeddings)\n",
    "        top_k_indices = np.argsort(similarities[0])[-k:][::-1]\n",
    "        return df.iloc[top_k_indices]['case_id'].tolist()\n",
    "\n",
    "    return retrieve\n",
    "\n",
    "# 4. Evaluasi\n",
    "def evaluate_retrieval(retriever, queries):\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': []}\n",
    "\n",
    "    for qid, query in queries.items():\n",
    "        retrieved = retriever(query['text'], k=5)\n",
    "        relevant = query['relevant_cases']\n",
    "\n",
    "        # Hitung metrik\n",
    "        tp = len(set(retrieved) & set(relevant))\n",
    "        precision = tp / len(retrieved) if len(retrieved) > 0 else 0\n",
    "        recall = tp / len(relevant) if len(relevant) > 0 else 0\n",
    "        accuracy = 1 if any(c in retrieved for c in relevant) else 0\n",
    "\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "\n",
    "    # Rata-rata metrik\n",
    "    return {k: sum(v)/len(v) for k,v in metrics.items()}\n",
    "\n",
    "# Jalankan evaluasi\n",
    "with open('data/eval/queries.json') as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "tfidf_retriever = tfidf_retrieval()\n",
    "bert_retriever = bert_retrieval()\n",
    "\n",
    "tfidf_metrics = evaluate_retrieval(tfidf_retriever, queries)\n",
    "bert_metrics = evaluate_retrieval(bert_retriever, queries)\n",
    "\n",
    "# Simpan hasil evaluasi\n",
    "metrics_df = pd.DataFrame({'TF-IDF': tfidf_metrics, 'BERT': bert_metrics})\n",
    "metrics_df.to_csv('data/eval/retrieval_metrics.csv')\n",
    "\n",
    "print(\"TF-IDF Metrics:\", tfidf_metrics)\n",
    "print(\"BERT Metrics:\", bert_metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
